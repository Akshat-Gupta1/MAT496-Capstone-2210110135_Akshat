{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Research Analyzer - Multi-Analyst News Research System\n",
                "\n",
                "This notebook implements a LangGraph-based research system that creates a team of specialized news analysts to conduct research on any topic and synthesize their findings into a comprehensive report.\n",
                "\n",
                "## Phase 1: Setup & Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "%%capture --no-stderr\n",
                "%pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python python-dotenv pydantic"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import os, getpass\n",
                "def _set_env(var: str):\n",
                "    if not os.environ.get(var):\n",
                "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
                "_set_env(\"OPENAI_API_KEY\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "_set_env(\"TAVILY_API_KEY\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 2: Data Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "from typing import List\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "class NewsAnalyst(BaseModel):\n",
                "    affiliation: str = Field(description=\"Primary affiliation of the analyst.\")\n",
                "    name: str = Field(description=\"Name of the analyst.\")\n",
                "    role: str = Field(description=\"Role of the analyst.\")\n",
                "    description: str = Field(description=\"Description of the analyst's focus and expertise.\")\n",
                "    @property\n",
                "    def persona(self) -> str:\n",
                "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
                "\n",
                "class AnalystTeam(BaseModel):\n",
                "    analysts: List[NewsAnalyst] = Field(description=\"Team of news analysts.\")\n",
                "\n",
                "class SearchQuery(BaseModel):\n",
                "    search_query: str = Field(None, description=\"Search query for news retrieval.\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 3: State Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import operator\n",
                "from typing import Annotated\n",
                "from typing_extensions import TypedDict\n",
                "from langgraph.graph import MessagesState\n",
                "\n",
                "class GenerateAnalystsState(TypedDict):\n",
                "    topic: str\n",
                "    max_analysts: int\n",
                "    human_analyst_feedback: str\n",
                "    analysts: List[NewsAnalyst]\n",
                "\n",
                "class AnalysisState(MessagesState):\n",
                "    max_num_turns: int\n",
                "    context: Annotated[list, operator.add]\n",
                "    analyst: NewsAnalyst\n",
                "    analysis: str\n",
                "    sections: Annotated[list, operator.add]\n",
                "\n",
                "class ResearchGraphState(TypedDict):\n",
                "    topic: str\n",
                "    max_analysts: int\n",
                "    human_analyst_feedback: str\n",
                "    analysts: List[NewsAnalyst]\n",
                "    sections: Annotated[list, operator.add]\n",
                "    introduction: str\n",
                "    content: str\n",
                "    conclusion: str\n",
                "    final_report: str"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 4: Prompt Templates"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "ANALYST_INSTRUCTIONS = \"\"\"You are tasked with creating a team of specialized news analysts. Follow these instructions:\n",
                "1. Review the topic: {topic}\n",
                "2. Examine any editorial feedback: {human_analyst_feedback}\n",
                "3. Determine the most important perspectives for comprehensive news analysis.\n",
                "4. Pick the top {max_analysts} perspectives.\n",
                "5. Assign one analyst to each perspective with relevant expertise.\"\"\"\n",
                "\n",
                "QUESTION_INSTRUCTIONS = \"\"\"You are a news analyst conducting research on {topic}.\n",
                "Your goal is to gather specific, actionable insights.\n",
                "Your analytical focus: {goals}\n",
                "Begin by introducing yourself, then pose your analytical questions.\n",
                "When satisfied, conclude with: \\\"Analysis complete!\\\"\"\"\"\n",
                "\n",
                "SEARCH_INSTRUCTIONS = \"\"\"Generate a search query for recent news and information.\n",
                "Focus on the latest developments relevant to the conversation.\"\"\"\n",
                "\n",
                "ANSWER_INSTRUCTIONS = \"\"\"You are a news information expert.\n",
                "Analyst focus: {goals}\n",
                "Answer using this context: {context}\n",
                "Guidelines: Use only provided context, include specific data, cite sources [1], [2], etc.\"\"\"\n",
                "\n",
                "SECTION_WRITER_INSTRUCTIONS = \"\"\"You are a news report writer.\n",
                "Create a concise section based on analyst research.\n",
                "Structure: ## {focus} (title), ### Key Findings, ### Analysis, ### Sources\n",
                "Maximum 300 words. Use numbered sources.\"\"\"\n",
                "\n",
                "REPORT_WRITER_INSTRUCTIONS = \"\"\"You are creating a comprehensive news report on: {topic}\n",
                "Task: Review all analyst sections, identify key insights, synthesize into cohesive narrative.\n",
                "Format: Use markdown, start with ## News Analysis, preserve citations, create ## Sources section.\n",
                "Analyst sections: {context}\"\"\"\n",
                "\n",
                "INTRODUCTION_INSTRUCTIONS = \"\"\"Write a compelling introduction for an analysis report on {topic}.\n",
                "Target 100 words. Use markdown. Create # title, then ## Introduction section.\n",
                "Report sections: {formatted_str_sections}\"\"\"\n",
                "\n",
                "CONCLUSION_INSTRUCTIONS = \"\"\"Write a conclusion for an analysis report on {topic}.\n",
                "Target 100 words. Use markdown. Use ## Conclusion header.\n",
                "Report sections: {formatted_str_sections}\"\"\""
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Phase 5: Analyst Generation\n",
                "\n",
                "Create the analyst generation nodes and subgraph."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "from IPython.display import Image, display\n",
                "from langgraph.graph import START, END, StateGraph\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
                "\n",
                "def create_analysts(state: GenerateAnalystsState):\n",
                "    \"\"\"Create news analysts based on the topic.\"\"\"\n",
                "    topic = state['topic']\n",
                "    max_analysts = state['max_analysts']\n",
                "    human_analyst_feedback = state.get('human_analyst_feedback', '')\n",
                "    \n",
                "    structured_llm = llm.with_structured_output(AnalystTeam)\n",
                "    system_message = ANALYST_INSTRUCTIONS.format(\n",
                "        topic=topic, human_analyst_feedback=human_analyst_feedback, max_analysts=max_analysts\n",
                "    )\n",
                "    analysts = structured_llm.invoke(\n",
                "        [SystemMessage(content=system_message)] + [HumanMessage(content=\"Generate the analyst team.\")]\n",
                "    )\n",
                "    return {\"analysts\": analysts.analysts}\n",
                "\n",
                "def human_feedback(state: GenerateAnalystsState):\n",
                "    \"\"\"No-op node for interruption.\"\"\"\n",
                "    pass\n",
                "\n",
                "def should_continue(state: GenerateAnalystsState):\n",
                "    \"\"\"Return the next node to execute.\"\"\"\n",
                "    if state.get('human_analyst_feedback', None):\n",
                "        return \"create_analysts\"\n",
                "    return END\n",
                "\n",
                "print(\"âœ“ Analyst generation functions defined!\")"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Build analyst generation graph\n",
                "builder = StateGraph(GenerateAnalystsState)\n",
                "builder.add_node(\"create_analysts\", create_analysts)\n",
                "builder.add_node(\"human_feedback\", human_feedback)\n",
                "builder.add_edge(START, \"create_analysts\")\n",
                "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
                "builder.add_conditional_edges(\"human_feedback\", should_continue, [\"create_analysts\", END])\n",
                "\n",
                "memory = MemorySaver()\n",
                "analyst_graph = builder.compile(checkpointer=memory)\n",
                "\n",
                "display(Image(analyst_graph.get_graph(xray=1).draw_mermaid_png()))"
            ],
            "outputs": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Test analyst generation\n",
                "max_analysts = 3\n",
                "topic = \"Artificial Intelligence Safety Regulations\"\n",
                "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "for event in analyst_graph.stream({\"topic\": topic, \"max_analysts\": max_analysts}, thread, stream_mode=\"values\"):\n",
                "    analysts = event.get('analysts', '')\n",
                "    if analysts:\n",
                "        for analyst in analysts:\n",
                "            print(f\"Name: {analyst.name}\")\n",
                "            print(f\"Role: {analyst.role}\")\n",
                "            print(f\"Affiliation: {analyst.affiliation}\")\n",
                "            print(\"-\" * 50)"
            ],
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}